{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dn1NrYAcmQLZ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from google.colab import files\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZsrmeKzvmcfe",
    "outputId": "8f028ca7-b9b9-4d52-871c-291e2a03a56c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "t78sahfQmeiO",
    "outputId": "78462bb9-15df-41e8-db81-799e5369519e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'data.zip'"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from shutil import copyfile\n",
    "copyfile('/gdrive/MyDrive/SoML-50.zip', 'data.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZqMVHx-Pmijo"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "M, N = 128, 128\n",
    "\n",
    "def image_split(img_location, output_folder, idx):\n",
    "    im = Image.open(img_location)\n",
    "    im = np.array(im)\n",
    "    tiles = [im[x:x+M,y:y+N] for x in range(0,im.shape[0],M) for y in range(0,im.shape[1],N)]\n",
    "    img = Image.fromarray(tiles[0], 'L')\n",
    "    img.save(output_folder + str(idx) + \"a.jpg\")\n",
    "    img = Image.fromarray(tiles[1], 'L')\n",
    "    img.save(output_folder + str(idx) + \"b.jpg\")\n",
    "    img = Image.fromarray(tiles[2], 'L')\n",
    "    img.save(output_folder + str(idx) + \"c.jpg\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ByLmZzxm3FI"
   },
   "outputs": [],
   "source": [
    "! mkdir divided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FSumVQ7Omz4E",
    "outputId": "559cf312-3b33-4e4c-9c2c-1610d1d91d81",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "12000\n",
      "12500\n",
      "13000\n",
      "13500\n",
      "14000\n",
      "14500\n",
      "15000\n",
      "15500\n",
      "16000\n",
      "16500\n",
      "17000\n",
      "17500\n",
      "18000\n",
      "18500\n",
      "19000\n",
      "19500\n",
      "20000\n",
      "20500\n",
      "21000\n",
      "21500\n",
      "22000\n",
      "22500\n",
      "23000\n",
      "23500\n",
      "24000\n",
      "24500\n",
      "25000\n",
      "25500\n",
      "26000\n",
      "26500\n",
      "27000\n",
      "27500\n",
      "28000\n",
      "28500\n",
      "29000\n",
      "29500\n",
      "30000\n",
      "30500\n",
      "31000\n",
      "31500\n",
      "32000\n",
      "32500\n",
      "33000\n",
      "33500\n",
      "34000\n",
      "34500\n",
      "35000\n",
      "35500\n",
      "36000\n",
      "36500\n",
      "37000\n",
      "37500\n",
      "38000\n",
      "38500\n",
      "39000\n",
      "39500\n",
      "40000\n",
      "40500\n",
      "41000\n",
      "41500\n",
      "42000\n",
      "42500\n",
      "43000\n",
      "43500\n",
      "44000\n",
      "44500\n",
      "45000\n",
      "45500\n",
      "46000\n",
      "46500\n",
      "47000\n",
      "47500\n",
      "48000\n",
      "48500\n",
      "49000\n",
      "49500\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 50001):\n",
    "  if (i % 500 == 0): print(i)\n",
    "  image_split(\"/content/SoML-50/data/\" + str(i) + '.jpg', 'divided/', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Q-xadecnRil"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c21-8oxL6QX7",
    "outputId": "0226a475-b573-4b9a-d3ef-ba0656b41461"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6490 images belonging to 14 classes.\n",
      "Found 854 images belonging to 14 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    \"/content/data/train\", \n",
    "    target_size=(128, 128),\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=128,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    \"/content/data/test\", \n",
    "    target_size=(128, 128),\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=128,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "veshefd3-N_v"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "                             tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=(128, 128, 1)),\n",
    "                             tf.keras.layers.MaxPooling2D(2, 2),\n",
    "                             tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "                             tf.keras.layers.MaxPooling2D(2, 2),\n",
    "                             tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "                             tf.keras.layers.MaxPooling2D(2, 2),\n",
    "                             tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "                             tf.keras.layers.MaxPooling2D(2, 2),\n",
    "                             tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),\n",
    "                             tf.keras.layers.Flatten(),\n",
    "                             tf.keras.layers.Dense(128, activation='relu'),\n",
    "                             tf.keras.layers.Dense(64, activation='relu'),\n",
    "                             tf.keras.layers.Dense(14, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0H0N032g-SoM"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2pLRPNlx-Vns",
    "outputId": "a228c008-0f57-4671-bfc5-438015303221"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 126, 126, 128)     1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 63, 63, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 61, 61, 64)        73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 16)          4624      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 14)                910       \n",
      "=================================================================\n",
      "Total params: 149,470\n",
      "Trainable params: 149,470\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lq7YEUw2-XmZ",
    "outputId": "00fa6996-dda7-4c22-ede0-c4c769dc85e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 3/49 [>.............................] - ETA: 4:17 - loss: 2.6386 - accuracy: 0.0755"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator, \n",
    "    steps_per_epoch=49,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=8,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TgmVWYKG-bSP",
    "outputId": "7d294ffe-5f99-4f78-e874-3da75f0e46df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1218 - accuracy: 0.9590WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 8 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 275s 6s/step - loss: 0.1218 - accuracy: 0.9590 - val_loss: 0.2528 - val_accuracy: 0.9239\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 264s 5s/step - loss: 0.1061 - accuracy: 0.9651\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 264s 5s/step - loss: 0.0868 - accuracy: 0.9744\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 264s 5s/step - loss: 0.0561 - accuracy: 0.9830\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 265s 5s/step - loss: 0.0513 - accuracy: 0.9851\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 265s 5s/step - loss: 0.0472 - accuracy: 0.9838\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 265s 5s/step - loss: 0.0337 - accuracy: 0.9887\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 266s 5s/step - loss: 0.0151 - accuracy: 0.9961\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 265s 5s/step - loss: 0.0137 - accuracy: 0.9962\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator, \n",
    "    steps_per_epoch=49,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=8,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8sPqx_m7Ku71"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Symbol Recognizer",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
