{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xm2DoW5ar_wJ",
    "outputId": "ae3e73e6-97f6-4934-bb69-942aef1902a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip \"/gdrive/My Drive/classified.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AckceJqCwj_d"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from google.colab import files\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LgbcuWDSzlm4"
   },
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WV-3U82eszTV",
    "outputId": "4c6396eb-5435-4692-e0b0-aafd0d2d86cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13544 images belonging to 14 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    \"classified/\", \n",
    "    target_size=(128, 128),\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=64,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# validation_generator = train_datagen.flow_from_directory(\n",
    "#     \"classified/\", \n",
    "#     target_size=(128, 128),\n",
    "#     color_mode=\"grayscale\",\n",
    "#     batch_size=64,\n",
    "#     class_mode='categorical',\n",
    "#     subset='validation'\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QrScwMj6xJ0s"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "                             tf.keras.layers.Dropout(.2, input_shape=(128, 128, 1)),\n",
    "                             tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "                             tf.keras.layers.MaxPooling2D(2, 2),\n",
    "                             tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "                             tf.keras.layers.MaxPooling2D(2, 2),\n",
    "                             tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "                             tf.keras.layers.MaxPooling2D(2, 2),\n",
    "                             tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "                              tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "                             tf.keras.layers.Flatten(),\n",
    "                             tf.keras.layers.Dense(128, activation='relu'),\n",
    "                             tf.keras.layers.Dense(64, activation='relu'),\n",
    "                             tf.keras.layers.Dense(14, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NNBwxJujxRDc"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XRRz_CZqxTyo",
    "outputId": "83317b0d-ede7-45d1-8db4-4cd532099f9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout_4 (Dropout)          (None, 128, 128, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 126, 126, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 61, 61, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_65 (Conv2D)           (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 128)               819328    \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 14)                910       \n",
      "=================================================================\n",
      "Total params: 930,414\n",
      "Trainable params: 930,414\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8q3Vb0utxVJ6",
    "outputId": "1e4e2a77-c298-4bd3-a1b5-69fa2d8fcb95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "211/211 [==============================] - 8s 37ms/step - loss: 1.4154 - accuracy: 0.5375\n",
      "Epoch 2/10\n",
      "211/211 [==============================] - 8s 37ms/step - loss: 0.3015 - accuracy: 0.9085\n",
      "Epoch 3/10\n",
      "211/211 [==============================] - 8s 37ms/step - loss: 0.1675 - accuracy: 0.9501\n",
      "Epoch 4/10\n",
      "211/211 [==============================] - 8s 37ms/step - loss: 0.1125 - accuracy: 0.9655\n",
      "Epoch 5/10\n",
      "211/211 [==============================] - 8s 37ms/step - loss: 0.0940 - accuracy: 0.9742\n",
      "Epoch 6/10\n",
      "211/211 [==============================] - 8s 37ms/step - loss: 0.0751 - accuracy: 0.9792\n",
      "Epoch 7/10\n",
      "211/211 [==============================] - 8s 37ms/step - loss: 0.0628 - accuracy: 0.9826\n",
      "Epoch 8/10\n",
      "211/211 [==============================] - 8s 37ms/step - loss: 0.0570 - accuracy: 0.9832\n",
      "Epoch 9/10\n",
      "211/211 [==============================] - 8s 37ms/step - loss: 0.0531 - accuracy: 0.9845\n",
      "Epoch 10/10\n",
      "211/211 [==============================] - 8s 37ms/step - loss: 0.0426 - accuracy: 0.9870\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator, \n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=10,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XzgM65vwyfvY",
    "outputId": "5a3e87be-f8ae-46ef-fa0e-c778e13f30b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.0313 - accuracy: 0.9886 - val_loss: 0.0335 - val_accuracy: 0.9911\n",
      "Epoch 2/10\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.0317 - accuracy: 0.9886 - val_loss: 0.0496 - val_accuracy: 0.9888\n",
      "Epoch 3/10\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.0330 - accuracy: 0.9885 - val_loss: 0.0587 - val_accuracy: 0.9844\n",
      "Epoch 4/10\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.0330 - accuracy: 0.9889 - val_loss: 0.0598 - val_accuracy: 0.9918\n",
      "Epoch 5/10\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.0324 - accuracy: 0.9881 - val_loss: 0.0347 - val_accuracy: 0.9896\n",
      "Epoch 6/10\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.0324 - accuracy: 0.9876 - val_loss: 0.0460 - val_accuracy: 0.9926\n",
      "Epoch 7/10\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.0291 - accuracy: 0.9883 - val_loss: 0.0343 - val_accuracy: 0.9926\n",
      "Epoch 8/10\n",
      "211/211 [==============================] - 8s 40ms/step - loss: 0.0268 - accuracy: 0.9889 - val_loss: 0.0309 - val_accuracy: 0.9911\n",
      "Epoch 9/10\n",
      "211/211 [==============================] - 8s 40ms/step - loss: 0.0264 - accuracy: 0.9884 - val_loss: 0.0381 - val_accuracy: 0.9926\n",
      "Epoch 10/10\n",
      "211/211 [==============================] - 8s 40ms/step - loss: 0.0275 - accuracy: 0.9889 - val_loss: 0.0358 - val_accuracy: 0.9918\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator, \n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=10\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OMKsFHeA4trr",
    "outputId": "97e6b457-8a3c-4ebc-8cf7-d267b3e2825f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: recognizer/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('recognizer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lrEmwoMe8N8r",
    "outputId": "fdfbb29e-860c-4fa7-ae3d-148697805484"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: recognizer/ (stored 0%)\n",
      "  adding: recognizer/keras_metadata.pb (deflated 93%)\n",
      "  adding: recognizer/variables/ (stored 0%)\n",
      "  adding: recognizer/variables/variables.index (deflated 70%)\n",
      "  adding: recognizer/variables/variables.data-00000-of-00001 (deflated 18%)\n",
      "  adding: recognizer/saved_model.pb (deflated 89%)\n",
      "  adding: recognizer/assets/ (stored 0%)\n"
     ]
    }
   ],
   "source": [
    "! zip -r recognizer.zip recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pQodkfnh8TQ-",
    "outputId": "95c54ed8-de60-458e-81cb-1cf47bacd361"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['42.jpg', 2], ['63.jpg', 63], ['41.jpg', 7], ['43.jpg', 18], ['64.jpg', 2]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import csv\n",
    "\n",
    "dic = {1: 8, 2: 5, 3: 4, 5: 9, 6: 1, 8: 7, 9: 6, 10: 3, 12: 2, 13: 0}\n",
    "operators = [0, 4, 7, 11]\n",
    "\n",
    "\n",
    "def calculate(array):\n",
    "    cnt = 0\n",
    "\n",
    "    numbers = []\n",
    "    to_do = 0\n",
    "\n",
    "\n",
    "    for i in array:\n",
    "        if i in operators:\n",
    "            cnt += 1\n",
    "            to_do = i\n",
    "        else:\n",
    "            numbers.append(dic[i])\n",
    "\n",
    "    if (cnt != 1): return 0\n",
    "    try:\n",
    "        if (to_do == 0): return numbers[0] / numbers[1]\n",
    "        if (to_do == 4): return numbers[0] - numbers[1]\n",
    "        if (to_do == 7): return numbers[0] + numbers[1]\n",
    "        if (to_do == 11): return numbers[0] * numbers[1]\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"folder\", type=str)\n",
    "args = parser.parse_args()\n",
    "\n",
    "folder_path = args.folder # image folder\n",
    "\n",
    "# folder_path = \"test/\"\n",
    "model_path = 'recognizer/' # model folder\n",
    "\n",
    "img_width, img_height = 384, 128\n",
    "M, N = 128, 128\n",
    "\n",
    "model = load_model(model_path) # load the trained model\n",
    "\n",
    "images = []\n",
    "files = os.listdir(folder_path)\n",
    "for img in files:\n",
    "    img = os.path.join(folder_path, img)\n",
    "    img = image.load_img(img, target_size=(img_height, img_width),color_mode='grayscale')\n",
    "    img = image.img_to_array(img)\n",
    "    img /= 255.\n",
    "    tiles = [img[x:x+M,y:y+N] for x in range(0,img.shape[0],M) for y in range(0,img.shape[1],N)]\n",
    "\n",
    "    img = np.expand_dims(tiles[0], axis=0)\n",
    "    images.append(img)\n",
    "    img = np.expand_dims(tiles[1], axis=0)\n",
    "    images.append(img)\n",
    "    img = np.expand_dims(tiles[2], axis=0)\n",
    "    images.append(img)\n",
    "\n",
    "images = np.vstack(images)\n",
    "classes = model.predict_classes(images, batch_size=10)\n",
    "k = list(classes)\n",
    "answers = []\n",
    "for i in range(len(files)):\n",
    "  p = k[3*i: 3*i + 3]\n",
    "  ans = 0\n",
    "  try:\n",
    "    ans = calculate(p)\n",
    "  except:\n",
    "    ans = 0\n",
    "  answers.append([files[i], ans])\n",
    "\n",
    "with open(\"team_name_2.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(answers)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "final-recogniser",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}